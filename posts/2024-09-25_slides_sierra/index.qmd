---
description: |
  Talk on Pl@ntnet and questions on citizen science
date: "2024-09-25"
image: "Celting_knot_color.svg"
image-alt: "Celting knot with partial coloring"
format:
  revealjs:
    # preview-links: true
    code-link: true
    highlight-style: a11y
    center: true


---

::: {.hidden}
{{

\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\1}{{1\hspace{-3.8pt} 1}}

}}
:::


<!-------------------------------------------------------------------------- -->
#### {#title-slide data-menu-title="Title Slide" background="#053660"}

[Citizen science for plant identification: insights from Pl@ntnet]{.custom-title}



<!-- <hr class="hr-teal"> -->

:::: {.columns}

::: {.column width="50%"}
[Joseph Salmon]{.custom-subtitle2}

[IMAG, Univ Montpellier, CNRS, Montpellier]{.custom-subtitle3}

[Institut Universitaire de France (IUF)]{.custom-subtitle3}

:::

::: {.column width="40%" }
<div style="text-align: center;">


![](../../images/logo_um_2022_rouge_RVB.svg){width=61%}
![](../../images/LogoIUF.svg){width=61%} <!-- Incrementally added -->

::: {.fragment}
![](../../images/arrow_nunito.svg){width=61%}
![](../../images/inr_logo_rouge.svg){width=61%} <!-- Incrementally added -->
:::
</div>
:::

::::
<!-------------------------------------------------------------------------- -->


<!-------------------------------------------------------------------------- -->
### {{< iconify iconoir:flower >}}  Flower power in Montpellier {{< iconify iconoir:flower >}}  {.large-header}
<hr>


Mainly joint work with:

- **Tanguy Lefort** (Univ. Montpellier, IMAG)
- **Benjamin Charlier** (Univ. Montpellier, IMAG)
- **Camille Garcin** (Univ. Montpellier, IMAG)
- **Maximilien Servajean** (Univ. Paul-Val√©ry-Montpellier, LIRMM, Univ. Montpellier)
- **Alexis Joly** (Inria, LIRMM, Univ. Montpellier)

::::{.columns style='display: flex !important'}

::: {.column width="30%"}

:::

::: {.column  align="center" style='display: flex; justify-content: center; align-items: center;'}
and from
:::

::: {.column width="30%"}

:::

::::



::::{.columns style='display: flex !important'}

::: {.column width="10%"}

:::

::: {.column align="center" style='display: flex; justify-content: center; align-items: center;'}
![](images/plantnet-logo-title.26755cd.svg){width=100%}
:::

::: {.column width="10%"}

:::

::::

- **Pierre Bonnet** (CIRAD, AMAP)
- **Antoine Affouard**, **Jean-Christophe Lombardo**, **Titouan Lorieul**, **Mathias Chouet** (Inria, LIRMM, Univ. Montpellier)
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
# Pl@ntNet description {.section-background}
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
### Pl@ntNet:  ML for citizen science
<hr>

::::{.columns}

::: {.column width="30%"}
![](images/plantnet-logo-title.26755cd.svg){width=106%}
:::

::: {.column width="69%"}
A **citizen science** platform using machine learning to help people identify plants with their mobile phones
:::

::::
<!-------------------------------------------------------------------------- -->




<!-------------------------------------------------------------------------- -->
::::{.columns style='display: flex !important'}

::: {.column width="65%"}

<div style="text-align: center;">


<img src="images/plantnet_app.jpg" width="26%" align="middle">

<img src="images/AppStoreandGooglePlay.svg" width="35%" align="middle">

</div>

- **Website**: [https://plantnet.org/](https://plantnet.org/)
- **[Note]{.underline}**: no mushroom identification!

:::


::: {.column width="35%"}
![](images/plantnet_image_ambiguity_js.svg){width=62%}
:::

::::
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
### {{< iconify hugeicons:chatting-01 >}} Pl@ntNet: usage and popularity
<hr>

:::: {.columns}
::: {.column width="53%"}
<!-- ![](images/plantnet-logo-title.26755cd.svg){width=35%} -->

[https://identify.plantnet.org/stats](https://identify.plantnet.org/stats){.scriptsize}


- Start in 2011, now **25M+ users**
- **200+** countries
- Up to **2M** image uploaded/day
- **50K** species
- **1B+** total images
- **10M+** labeled / validated

:::

::: {.column width="45%"}
![](images/map_plantnet.png){width=100%}
:::

::::

<div style="text-align: center;">

<img src="images/plantnet_usage_rasterized.svg" width="84%" align="middle" >

</div>
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
### Pl@ntNet & Cooperative Learning
<!-- <hr> -->
<div style="text-align: center;">

<img src="images/plantnet_schema_global_js.svg" width="90%" align="middle" >
<!-- https://lvngd.com/blog/how-embed-google-font-svg/ -->
</div>
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
### {{< iconify vaadin:hourglass-start >}} Chronology of Pl@ntNet

<br>

<img src="images/PlantNet-overview-Janv-2022_js.svg" width="90%" align="middle" >
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
### {{< iconify eos-icons:science >}} Scientific challenges
<hr>
<br>

[**Motivation**]{.underline}: excellent app ... but not a perfect app; **How to improve?**


- Community effort: machine learning, ecology, engineering, amateurs</li>
- Many open problems (theoretical/practical)</li>
- Need for methodological/computational breakthrough</li>

**Note:** I am mostly innocent; started working with the Pl@ntNet team in 2020
<!-------------------------------------------------------------------------- -->


<!-------------------------------------------------------------------------- -->
# Contributions {.section-background}
<!-------------------------------------------------------------------------- -->


<!-------------------------------------------------------------------------- -->
### {{<iconify bxs:user-detail>}} Associated personal contributions
<hr>

<br>

:::: {.columns }

::: {.column width="68%"}

- **Pl@ntNet-300K** [@Garcin_Joly_Bonnet_Affouard_Lombardo_Chouet_Servajean_Salmon21]: Creation and **release** of a large-scale dataset sharing the same property as Pl@ntNet; available for the community to improve learning systems

:::

::: {.column width="29%"}

<center>
<img src="images/sample_genus.svg" width="62%" align="middle">
</center>

:::

::::

::: fragment

:::: columns

::: {.column width="68%"}

- **Learning & crowd-sourced data** [@Lefort_Charlier_Joly_Salmon22]: How to leverage multiple labels per image to improve the model? Need to **assert quality**: the workers, the images/labels, the model, etc.

:::

::: {.column width="29%"}
<center>
<img src="images/fullpipeline_small.svg" width="78%" align="middle">
</center>

:::

::::

:::

::: fragment

:::: columns

::: {.column width="68%"}

- **Top-K learning** [@Garcin_Servajean_Joly_Salmon22]: Driven by theory, introduce new loss to cope with Pl@ntNet constraints to **output multiple labels** (e.g., UX, Deep Learning framework, etc.)

:::

::: {.column width="29%"}
<center>
<img src="images/LossGarcin_k=2_9_margin_5.svg" width="78%" align="middle">
</center>

:::

::::

:::
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
## Dataset release: Pl@ntNet-300K {.section-background-small}
<!-------------------------------------------------------------------------- -->


<!-------------------------------------------------------------------------- -->
### {{<iconify gravity-ui:magnifier>}} A need for new benchmarks
<hr>
<br>
**Popular datasets limitations:**

- structure of labels too simplistic (CIFAR-10, CIFAR-100)
  - might have tasks too easy to discriminate
  - might be too well-balanced (same number of images per class)
- contains duplicate, low-quality, or irrelevant images


**[Motivation]{.underline}**:

release a large-scale dataset **sharing similar features** as the Pl@ntNet dataset to foster research in plant identification

$\implies$ Pl@ntNet-300K [@Garcin_Joly_Bonnet_Affouard_Lombardo_Chouet_Servajean_Salmon21]
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
### Intra-class variability

::: {layout-nrow=2}

![Guizotia abyssinica](images/6_a.jpg){width=93%}

![Diascia rigescens](images/7_a.jpg){width=93%}

![Lapageria rosea](images/8_a.jpg){width=93%}

![Casuarina cunninghamiana](images/9_a.jpg){width=93%}

![Freesia alba](images/10_a.jpg){width=93%}

![Guizotia abyssinica](images/6_b.jpg){width=93%}

![Diascia rigescens](images/7_b.jpg){width=93%}

![Lapageria rosea](images/8_b.jpg){width=93%}

![Casuarina cunninghamiana](images/9_b.jpg){width=93%}

![Freesia alba](images/10_b.jpg){width=93%}

:::

<center>
**Based on pictures only, plant species are challenging to discriminate!**
</center>
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
### Inter-class ambiguity


::: {layout-nrow=2}

![Cirsium rivulare](images/1_a.jpg){width=93%}

![Chaerophyllum aromaticum](images/2_a.jpg){width=93%}

![Conostomium kenyense](images/3_a.jpg){width=93%}

![Adenostyles leucophylla](images/4_a.jpg){width=93%}

![Sedum montanum](images/5_a.jpg){width=93%}

![Cirsium tuberosum](images/1_b.jpg){width=93%}

![Chaerophyllum temulum](images/2_b.jpg){width=93%}

![Conostomium quadrangulare](images/3_b.jpg){width=93%}

![Adenostyles alliariae](images/4_b.jpg){width=93%}

![Sedum rupestre](images/5_b.jpg){width=93%}

:::

<center>
**Based on pictures only, plant species are challenging to discriminate!**
</center>
<!-------------------------------------------------------------------------- -->


<!-------------------------------------------------------------------------- -->
## Sampling bias {.section-background-small}
<!-------------------------------------------------------------------------- -->


<!-------------------------------------------------------------------------- -->
### {{<iconify gis:globe-earth-alt>}} Geographic bias


<div style="display: flex; flex-direction: column;">
![](images/plantnet_bias_geographic04_04_2024.png){width=100%}

<center>Spatial density of images collected by Pl@ntNet (13/04/2024)</center>
</div>
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
### {{<iconify fluent:food-20-filled>}} Food bias 
<hr>

<br>

Top-5 most observed plant species in Pl@ntNet (13/04/2024):

<br>


::: {layout-nrow=1  .v-center-container}
**25134 obs.**
![Echium vulgare L.](images/Echium_vulgare_L.jpeg){width=200px height=200px}
*Echium vulgare L.*

**24720 obs.**
![Ranunculus ficaria L.](images/Ranunculus_ficaria_L.jpeg){width=200px height=200px}
*Ranunculus ficaria L.*

**24103 obs.**
![Prunus spinosa L.](images/Prunus_spinosa_L.jpeg){width=200px height=200px}
*Prunus spinosa L.*

**23288 obs.**
![Zea mays L.](images/Zea_mays_L.jpeg){width=200px height=200px}
*Zea mays L.*

**23075 obs.**
![Alliaria petiolata](images/Alliaria_petiolata.jpeg){width=200px height=200px}
*Alliaria petiolata*
:::


### {{<iconify ri:sparkling-2-line>}} Beauty bias

:::: {.columns}

::: {.column  style='text-align: center;'}
**10753 obs.**

![](images/Centaurea_jacea.jpg){width=72%}

*Centaurea jacea*
:::


::: {.column  style='text-align: center;'}

**6 obs.**

![](images/Cenchrus_agrimonioides.jpg){width=72%}

*Cenchrus agrimonioides*
:::

::::
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->

### {{<iconify emojione-monotone:straight-ruler>}} Size bias


:::: {.columns style='display: flex !important'}

::: {.column  style='text-align: center;'}

**8376 obs.**

![](images/Magnolia_grandiflora.png){width=75%}

*Magnolia grandiflora*

:::


::: {.column  style='text-align: center;'}

![](images/rule.png){width=20%}


:::

::: {.column  style='text-align: center;'}

**413 obs.**

![](images/Moehringia_trinervia.png){width=25%}

*Moehringia trinervia*
:::

::::
<!-------------------------------------------------------------------------- -->

### Many more biases ...
<hr>

<br>

- Selection bias
    - Convenience sampling:  **easily** vs. *hardly* accessible
    - Preference for certain species: **visibility** / **ease of identification**
    - Subjective bias: selection based on **personal judgment**, may not be random or representative
     - Rare species: **rare** or **endangered** species may be under-represented

- Temporal bias / seasonal variation: **seasonal changes** in plant characteristics
- ...

<!-------------------------------------------------------------------------- -->

### Construction of Pl@ntNet-300K {style="text-align: center;"}


<center>
![](images/sample_genus.svg){width=80%}

Sample at genus level to preserve intra-genus ambiguity: use **hierarchical structure**
</center>

<!-------------------------------------------------------------------------- -->
### {{<iconify icon-park-solid:chart-histogram-two>}} Species distribution & long tail 
<hr>

:::: {.columns style='display: flex !important'}

::: {.column width=82%}

::: {.r-stack}
![](images/lorentz_plantnet.svg){.fragment width=100% fragment-index=2}

![](images/lorentz_plantnet300K.svg){.fragment width=100% fragment-index=3}

![](images/lorentz_with_Imagenet.svg){.fragment width=100% fragment-index=4}

![](images/lorentz_with_CIFAR_Imagenet.svg){.fragment width=100% fragment-index=5}

:::

:::

::: {.column style='text-align: center;'}

<br>

:::{.fragment fragment-index=1}
- Earth: 300K+ species
- Pl@ntNet: 50K+ species
- Pl@ntNet-300K: 1K+ species
:::

:::{.fragment fragment-index=3}
**[Note]{.underline}**: long tail preserved by genera subsampling
:::
:::

::::

<br>

:::{.fragment fragment-index=2}

<center>
**80% of species | 11% of images** $\iff$ **20% of species | 89% of images**
</center>

:::


### {{<iconify eos-icons:database>}} Details on Pl@ntNet-300K
<hr>
<br>


:::: {.columns style='display: flex !important'}

::: {.column }

[**Caracteristics**]{.underline}:

<br>

- **306,146** color images
- size : 32 GB
- Labels: K=**1,081** species
- Required **2,079,003** volunteers "workers"
:::


::: {.column width=55%}
:::{.fragment}

<br>

<center>
**Zenodo, 1 click download**

[https://zenodo.org/record/5645731](https://zenodo.org/record/5645731)

<br>

**Code to train models**

[https://github.com/plantnet/PlantNet-300K](https://github.com/plantnet/PlantNet-300K)
</center>

:::

:::

::::
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
# Votes, labels & aggregation {.section-background}
<!-------------------------------------------------------------------------- -->


### {{<iconify fluent:vote-24-filled>}} Pl@ntNet online "votes"
<hr>


<center>
![](images/plantnet_online.png){width=70%}

Link: [https://identify.plantnet.org/weurope/observations/1012500059](https://identify.plantnet.org/weurope/observations/1012500059)
</center>

### {{<iconify pajamas:labels>}} What about labels?
<hr>

<br>

- Images from users... so are the labels!

- But **users** can be wrong or **not experts**

- **Several labels** can be available per image!


### {{<iconify jam:write-f>}} Users can make corrections {.center style="text-align: center;"}

![](images/plantnet_corrected.png){width=90%}

---

### But sometimes users can't be trusted {.center style="text-align: center;"}


<center>
::: {.r-stack}

![](images/vanessa_corrected.png){width=50%}

![](images/right_vanessa_corrected.png){.fragment width=50% fragment-index=1}

:::


Link: [https://identify.plantnet.org/weurope/observations/1012500059](https://identify.plantnet.org/weurope/observations/1012500059)

</center>
<!-------------------------------------------------------------------------- -->





<!-------------------------------------------------------------------------- -->
### {{<iconify mdi:crowdsource>}} Crowdsourcing for classification
<hr>
<br>


**The good, the bad and the ugly**



::: {.fragment}
- The good: fast, easy, cheap data collection
:::

::: {.fragment}
- The bad: noisy labels with different levels of expertise
:::

::: {.fragment}
- The ugly: (partly) missing theory, ad-hoc methods for noisy labels
:::
<!-------------------------------------------------------------------------- -->


<!-------------------------------------------------------------------------- -->
### {{<iconify fluent:clipboard-math-formula-32-regular>}} Notation

![](images/notation_smiley.svg){width=86%}
<!-------------------------------------------------------------------------- -->


<!-------------------------------------------------------------------------- -->
### Objective
<hr>
<br>
Provide for all images $x_i$ an aggregated label $\hat{y}_i$ based on the votes $y^{u}_i$ of the workers $u \in \mathcal{U}$.
<!-------------------------------------------------------------------------- -->


<!-------------------------------------------------------------------------- -->
### Majority Vote (MV) {.left}
<hr>
<br>
**Naive idea**: make users vote and take the most voted label for each image

![](images/MV_smiley.svg){width=95%}
<!-------------------------------------------------------------------------- -->



<!-------------------------------------------------------------------------- -->
### Majority Vote (more)
<br>

<div class="defini" data-text='Majority vote'>

$$
\forall x_i \in \mathcal{X}_{\text{train}},\quad
\hat y_i^{\text{MV}} = \argmax_{k\in [K]}
\Big(\sum\limits_{u\in\mathcal{U}(x_i)} \1_{\{y^{u}_i=k\}} \Big)
$$

</div>


**Properties**: output the most answered label

- <span style="color:#047C90;">‚úì</span> simple
- <span style="color:#047C90;">‚úì</span> adapted for any number of users
- <span style="color:#047C90;">‚úì</span> usually efficient, often few labelers sufficient (say < 5, [@Snow_OConnor_Jurafsky_Ng08] )
- <span style="color:red;">‚úó</span>  ineffective for borderline cases
- <span style="color:red;">‚úó</span>  suffer from spammers / adversarial users
<!-------------------------------------------------------------------------- -->





<!-------------------------------------------------------------------------- -->
### {#contact data-menu-title="Contact"}

![](https://raw.githubusercontent.com/josephsalmon/OrganizationFiles/master/inkscape/images/contact_js.svg)

<br>
<br>
<br>

<!-------------------------------------------------------------------------- -->



# Bibliographie {.section-background}


<!-------------------------------------------------------------------------- -->
### References
<hr>

::: {#refs}
:::
<!-------------------------------------------------------------------------- -->



